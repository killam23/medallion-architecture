{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43d3c551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: cassandra-driver in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (3.29.2)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: geomet<0.3,>=0.1 in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from cassandra-driver) (0.2.1.post1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.0.4)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from geomet<0.3,>=0.1->cassandra-driver) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->geomet<0.3,>=0.1->cassandra-driver) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "## installing required libraries\n",
    "!pip install cassandra-driver pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ba8bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to AstraDB\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your secure connect bundle\n",
    "ASTRA_DB_BUNDLE_PATH = 'secure-connect-hello.zip'\n",
    "\n",
    "# Set up the authentication and cluster\n",
    "def create_session():\n",
    "    cloud_config = {\n",
    "        'secure_connect_bundle': ASTRA_DB_BUNDLE_PATH\n",
    "    }\n",
    "    auth_provider = PlainTextAuthProvider('makUuXvvkAWdDyKrsMOvharq', '9W6d+7JwkA.HGaJOd62ZXjlvUx9xt_4W5_ctJtw4ES6.CFxK36huoyps6N9GzhtMlkEvRnpD4Nz_BnRc2NJK1Z+D47KsICzqrcZQ23WqZr+mHtZb2I,WqNDYF3,DvJK,')\n",
    "    cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
    "    session = cluster.connect()\n",
    "    return session\n",
    "\n",
    "session = create_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f048103c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "      <th>Item Type</th>\n",
       "      <th>Sales Channel</th>\n",
       "      <th>Order Priority</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>UnitsSold</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>UnitCost</th>\n",
       "      <th>TotalRevenue</th>\n",
       "      <th>TotalCost</th>\n",
       "      <th>TotalProfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Fruits</td>\n",
       "      <td>Offline</td>\n",
       "      <td>M</td>\n",
       "      <td>7/27/2012</td>\n",
       "      <td>443368995</td>\n",
       "      <td>7/28/2012</td>\n",
       "      <td>1593</td>\n",
       "      <td>9.33</td>\n",
       "      <td>6.92</td>\n",
       "      <td>14862.69</td>\n",
       "      <td>11023.56</td>\n",
       "      <td>3839.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Middle East and North Africa</td>\n",
       "      <td>Morocco</td>\n",
       "      <td>Clothes</td>\n",
       "      <td>Online</td>\n",
       "      <td>M</td>\n",
       "      <td>9/14/2013</td>\n",
       "      <td>667593514</td>\n",
       "      <td>10/19/2013</td>\n",
       "      <td>4611</td>\n",
       "      <td>109.28</td>\n",
       "      <td>35.84</td>\n",
       "      <td>503890.08</td>\n",
       "      <td>165258.24</td>\n",
       "      <td>338631.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia and Oceania</td>\n",
       "      <td>Papua New Guinea</td>\n",
       "      <td>Meat</td>\n",
       "      <td>Offline</td>\n",
       "      <td>M</td>\n",
       "      <td>5/15/2015</td>\n",
       "      <td>940995585</td>\n",
       "      <td>6/4/2015</td>\n",
       "      <td>360</td>\n",
       "      <td>421.89</td>\n",
       "      <td>364.69</td>\n",
       "      <td>151880.40</td>\n",
       "      <td>131288.40</td>\n",
       "      <td>20592.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>Djibouti</td>\n",
       "      <td>Clothes</td>\n",
       "      <td>Offline</td>\n",
       "      <td>H</td>\n",
       "      <td>5/17/2017</td>\n",
       "      <td>880811536</td>\n",
       "      <td>7/2/2017</td>\n",
       "      <td>562</td>\n",
       "      <td>109.28</td>\n",
       "      <td>35.84</td>\n",
       "      <td>61415.36</td>\n",
       "      <td>20142.08</td>\n",
       "      <td>41273.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Slovakia</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Offline</td>\n",
       "      <td>L</td>\n",
       "      <td>10/26/2016</td>\n",
       "      <td>174590194</td>\n",
       "      <td>12/4/2016</td>\n",
       "      <td>3973</td>\n",
       "      <td>47.45</td>\n",
       "      <td>31.79</td>\n",
       "      <td>188518.85</td>\n",
       "      <td>126301.67</td>\n",
       "      <td>62217.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Region           Country  Item Type Sales Channel  \\\n",
       "0            Sub-Saharan Africa      South Africa     Fruits       Offline   \n",
       "1  Middle East and North Africa           Morocco    Clothes        Online   \n",
       "2         Australia and Oceania  Papua New Guinea       Meat       Offline   \n",
       "3            Sub-Saharan Africa          Djibouti    Clothes       Offline   \n",
       "4                        Europe          Slovakia  Beverages       Offline   \n",
       "\n",
       "  Order Priority  Order Date   Order ID   Ship Date  UnitsSold  UnitPrice  \\\n",
       "0              M   7/27/2012  443368995   7/28/2012       1593       9.33   \n",
       "1              M   9/14/2013  667593514  10/19/2013       4611     109.28   \n",
       "2              M   5/15/2015  940995585    6/4/2015        360     421.89   \n",
       "3              H   5/17/2017  880811536    7/2/2017        562     109.28   \n",
       "4              L  10/26/2016  174590194   12/4/2016       3973      47.45   \n",
       "\n",
       "   UnitCost  TotalRevenue  TotalCost  TotalProfit  \n",
       "0      6.92      14862.69   11023.56      3839.13  \n",
       "1     35.84     503890.08  165258.24    338631.84  \n",
       "2    364.69     151880.40  131288.40     20592.00  \n",
       "3     35.84      61415.36   20142.08     41273.28  \n",
       "4     31.79     188518.85  126301.67     62217.18  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read data from CSV File\n",
    "import uuid\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\DELL\\sales_100.csv')\n",
    "\n",
    "# View first few rows to understand the structure\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19d6fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set Keyspace\n",
    "session.set_keyspace('hello')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c758652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inserting data from csv file to create bronze level \n",
    "from cassandra.query import SimpleStatement\n",
    "import uuid\n",
    "\n",
    "insert_query = session.prepare(\"\"\"\n",
    "    INSERT INTO sales_databronze(id, region, country, item_type, sales_channel, order_priority, order_date, order_id,\n",
    "                       ship_date, units_sold, unit_price, unit_cost, total_revenue, total_cost, total_profit)\n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "\"\"\")\n",
    "\n",
    "# Insert each row from DataFrame\n",
    "for _, row in df.iterrows():\n",
    "    session.execute(insert_query, (\n",
    "        uuid.uuid4(),\n",
    "        row['Region'],\n",
    "        row['Country'],\n",
    "        row['Item Type'],\n",
    "        row['Sales Channel'],\n",
    "        row['Order Priority'],\n",
    "        str(row['Order Date']),\n",
    "        int(row['Order ID']),\n",
    "        str(row['Ship Date']),\n",
    "        int(row['UnitsSold']),\n",
    "        float(row['UnitPrice']),\n",
    "        float(row['UnitCost']),\n",
    "        float(row['TotalRevenue']),\n",
    "        float(row['TotalCost']),\n",
    "        float(row['TotalProfit']),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c14f8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(id=UUID('8c2c2b8f-aaca-4265-9254-ec2b3c162a2a'), country='Iceland', item_type='Baby Food', order_date='10/2/2010', order_id=678230941, order_priority='M', region='Europe', sales_channel='Offline', ship_date='11/3/2010', total_cost=392492.04, total_profit=236007.32, total_revenue=628499.36, unit_cost=159.42, unit_price=255.28, units_sold=2462)\n",
      "Row(id=UUID('0b77c299-eaff-4d17-938f-3069295eaa79'), country='Italy', item_type='Cereal', order_date='11/30/2015', order_id=887409770, order_priority='C', region='Europe', sales_channel='Online', ship_date='12/5/2015', total_cost=366085.86, total_profit=276932.34, total_revenue=643018.2, unit_cost=117.11, unit_price=205.7, units_sold=3126)\n",
      "Row(id=UUID('1ae23538-6990-4f76-b7c9-4ebc3ee2bbdc'), country='Greece', item_type='Cereal', order_date='8/22/2015', order_id=887124383, order_priority='H', region='Europe', sales_channel='Online', ship_date='10/8/2015', total_cost=1015812.14, total_profit=768429.66, total_revenue=1784241.8, unit_cost=117.11, unit_price=205.7, units_sold=8674)\n",
      "Row(id=UUID('bf4e89c8-10c8-49d9-9a47-1ced2de9aa95'), country='South Korea', item_type='Meat', order_date='3/16/2016', order_id=297876536, order_priority='L', region='Asia', sales_channel='Offline', ship_date='4/20/2016', total_cost=2604251.29, total_profit=408465.2, total_revenue=3012716.49, unit_cost=364.69, unit_price=421.89, units_sold=7141)\n",
      "Row(id=UUID('80e9583d-6512-4e0a-8cfe-8617825fa516'), country='Uganda', item_type='Personal Care', order_date='6/19/2014', order_id=539471471, order_priority='M', region='Sub-Saharan Africa', sales_channel='Online', ship_date='7/21/2014', total_cost=25558.17, total_profit=11302.06, total_revenue=36860.23, unit_cost=56.67, unit_price=81.73, units_sold=451)\n"
     ]
    }
   ],
   "source": [
    "## verifying that the data is inserted into Bronze Level table \n",
    "rows = session.execute(\"SELECT * FROM sales_databronze LIMIT 5\")\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bc6ff52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded successfully to Astra DB!\n"
     ]
    }
   ],
   "source": [
    "## Inserting data into silver table \n",
    "import pandas as pd\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "# Load cleaned Silver layer data\n",
    "df = pd.read_csv(r'C:\\Users\\DELL\\sales_silver.csv')\n",
    "\n",
    "# Path to your secure connect bundle (unzipped folder)\n",
    "SECURE_CONNECT_BUNDLE_PATH = r'C:\\Users\\DELL\\secure-connect-hello.zip'\n",
    "\n",
    "# Set up Cassandra cluster with authentication\n",
    "cloud_config = {\n",
    "    'secure_connect_bundle': SECURE_CONNECT_BUNDLE_PATH\n",
    "}\n",
    "\n",
    "auth_provider = PlainTextAuthProvider('makUuXvvkAWdDyKrsMOvharq', '9W6d+7JwkA.HGaJOd62ZXjlvUx9xt_4W5_ctJtw4ES6.CFxK36huoyps6N9GzhtMlkEvRnpD4Nz_BnRc2NJK1Z+D47KsICzqrcZQ23WqZr+mHtZb2I,WqNDYF3,DvJK,')\n",
    "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
    "session = cluster.connect()\n",
    "\n",
    "# Set keyspace\n",
    "session.set_keyspace('hello')\n",
    "\n",
    "# Prepare insert statement\n",
    "insert_stmt = session.prepare(\"\"\"\n",
    "    INSERT INTO sales_datasilver (\n",
    "        order_id, region, country, item_type, sales_channel, order_priority,\n",
    "        order_date, ship_date, units_sold, unit_price, unit_cost,\n",
    "        total_revenue, total_cost, total_profit\n",
    "    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "\"\"\")\n",
    "\n",
    "# Insert rows into Astra\n",
    "for _, row in df.iterrows():\n",
    "    session.execute(insert_stmt, (\n",
    "        int(row['order_id']),\n",
    "        row['region'],\n",
    "        row['country'],\n",
    "        row['item_type'],\n",
    "        row['sales_channel'],\n",
    "        row['order_priority'],\n",
    "        row['order_date'],   # should be in 'YYYY-MM-DD'\n",
    "        row['ship_date'],\n",
    "        int(row['units_sold']),\n",
    "        float(row['unit_price']),\n",
    "        float(row['unit_cost']),\n",
    "        float(row['total_revenue']),\n",
    "        float(row['total_cost']),\n",
    "        float(row['total_profit'])\n",
    "    ))\n",
    "\n",
    "print(\"✅ Data loaded successfully to Astra DB!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faacfd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = session.execute(\"SELECT * FROM sales_datasilver\")\n",
    "data = [dict(row._asdict()) for row in rows]\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "607a4f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Dates\n",
    "df[\"order_date\"] = pd.to_datetime(df[\"order_date\"], errors=\"coerce\")\n",
    "df[\"ship_date\"] = pd.to_datetime(df[\"ship_date\"], errors=\"coerce\")\n",
    "\n",
    "# Drop nulls in critical columns\n",
    "df.dropna(subset=[\"order_date\", \"ship_date\", \"units_sold\", \"unit_price\", \"unit_cost\"], inplace=True)\n",
    "\n",
    "# Drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Fix order_priority\n",
    "priority_map = {\"L\": \"Low\", \"M\": \"Medium\", \"H\": \"High\", \"C\": \"Critical\"}\n",
    "df[\"order_priority\"] = df[\"order_priority\"].map(priority_map).fillna(\"Unknown\")\n",
    "\n",
    "# Normalize text\n",
    "df[\"sales_channel\"] = df[\"sales_channel\"].str.strip().str.lower()\n",
    "df[\"item_type\"] = df[\"item_type\"].str.strip().str.title()\n",
    "\n",
    "# Calculate delivery_days\n",
    "df[\"delivery_days\"] = (df[\"ship_date\"] - df[\"order_date\"]).dt.days\n",
    "\n",
    "# Remove negative values\n",
    "df = df[\n",
    "    (df[\"total_revenue\"] >= 0) &\n",
    "    (df[\"total_cost\"] >= 0) &\n",
    "    (df[\"total_profit\"] >= 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e240bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Table truncated. Ready to insert cleaned data.\n"
     ]
    }
   ],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "import pandas as pd\n",
    "\n",
    "# (Assuming your session is already created)\n",
    "\n",
    "# ⚠️ This removes all rows\n",
    "session.execute(\"TRUNCATE sales_silver\")\n",
    "\n",
    "print(\"✅ Table truncated. Ready to insert cleaned data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "185bc3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x1bff4862c70>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(\"ALTER TABLE sales_datasilver ADD delivery_days int;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6aec5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original file\n",
    "df = pd.read_csv(\"sales_silver.csv\")\n",
    "\n",
    "# Cleaning steps\n",
    "df[\"order_date\"] = pd.to_datetime(df[\"order_date\"], errors=\"coerce\")\n",
    "df[\"ship_date\"] = pd.to_datetime(df[\"ship_date\"], errors=\"coerce\")\n",
    "df.dropna(subset=[\"order_date\", \"ship_date\", \"units_sold\", \"unit_price\", \"unit_cost\"], inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df[\"order_priority\"] = df[\"order_priority\"].map({\"L\": \"Low\", \"M\": \"Medium\", \"H\": \"High\", \"C\": \"Critical\"}).fillna(\"Unknown\")\n",
    "df[\"sales_channel\"] = df[\"sales_channel\"].str.strip().str.lower()\n",
    "df[\"item_type\"] = df[\"item_type\"].str.strip().str.title()\n",
    "df[\"delivery_days\"] = (df[\"ship_date\"] - df[\"order_date\"]).dt.days\n",
    "df = df[\n",
    "    (df[\"total_revenue\"] >= 0) &\n",
    "    (df[\"total_cost\"] >= 0) &\n",
    "    (df[\"total_profit\"] >= 0)\n",
    "]\n",
    "\n",
    "# Save to cleaned file\n",
    "df.to_csv(\"sales_silver_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a02b1f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Raw rows: 99\n",
      "🧹 Removed rows with invalid dates: 0\n",
      "🧹 Removed rows with missing values in ['units_sold', 'unit_price', 'unit_cost']: 0\n",
      "🧹 Removed duplicate rows: 0\n",
      "🧹 Removed rows with negative values in ['total_revenue', 'total_cost', 'total_profit']: 0\n",
      "\n",
      "✅ Cleaned data saved to 'sales_silver_cleaned.csv'\n",
      "📊 Final cleaned row count: 99\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load raw (bronze) data\n",
    "df_raw = pd.read_csv(\"sales_silver.csv\")\n",
    "print(f\"🔹 Raw rows: {len(df_raw)}\")\n",
    "\n",
    "# Make a copy to clean\n",
    "df = df_raw.copy()\n",
    "\n",
    "# 1. Convert order_date and ship_date to datetime\n",
    "df[\"order_date\"] = pd.to_datetime(df[\"order_date\"], errors=\"coerce\")\n",
    "df[\"ship_date\"] = pd.to_datetime(df[\"ship_date\"], errors=\"coerce\")\n",
    "\n",
    "before = len(df)\n",
    "df = df.dropna(subset=[\"order_date\", \"ship_date\"])\n",
    "print(f\"🧹 Removed rows with invalid dates: {before - len(df)}\")\n",
    "\n",
    "# 2. Drop rows with nulls in important numeric columns\n",
    "important_cols = [\"units_sold\", \"unit_price\", \"unit_cost\"]\n",
    "before = len(df)\n",
    "df = df.dropna(subset=important_cols)\n",
    "print(f\"🧹 Removed rows with missing values in {important_cols}: {before - len(df)}\")\n",
    "\n",
    "# 3. Drop duplicates\n",
    "before = len(df)\n",
    "df = df.drop_duplicates()\n",
    "print(f\"🧹 Removed duplicate rows: {before - len(df)}\")\n",
    "\n",
    "# 4. Standardize order_priority\n",
    "priority_map = {\"L\": \"Low\", \"M\": \"Medium\", \"H\": \"High\", \"C\": \"Critical\"}\n",
    "df[\"order_priority\"] = df[\"order_priority\"].map(priority_map).fillna(\"Unknown\")\n",
    "\n",
    "# 5. Add delivery_days column\n",
    "df[\"delivery_days\"] = (df[\"ship_date\"] - df[\"order_date\"]).dt.days\n",
    "\n",
    "# 6. Drop rows with negative values in financial columns\n",
    "financial_cols = [\"total_revenue\", \"total_cost\", \"total_profit\"]\n",
    "before = len(df)\n",
    "df = df[\n",
    "    (df[\"total_revenue\"] >= 0) &\n",
    "    (df[\"total_cost\"] >= 0) &\n",
    "    (df[\"total_profit\"] >= 0)\n",
    "]\n",
    "print(f\"🧹 Removed rows with negative values in {financial_cols}: {before - len(df)}\")\n",
    "\n",
    "# 7. Normalize text fields\n",
    "df[\"sales_channel\"] = df[\"sales_channel\"].str.strip().str.lower()\n",
    "df[\"item_type\"] = df[\"item_type\"].str.strip().str.title()\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv(\"sales_silver_cleaned.csv\", index=False)\n",
    "print(f\"\\n✅ Cleaned data saved to 'sales_silver_cleaned.csv'\")\n",
    "print(f\"📊 Final cleaned row count: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86a4a6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Rows in cleaned CSV: 99\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"sales_silver_cleaned.csv\")\n",
    "print(f\"✅ Rows in cleaned CSV: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29f62717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region            0\n",
      "country           0\n",
      "item_type         0\n",
      "sales_channel     0\n",
      "order_priority    0\n",
      "order_date        0\n",
      "order_id          0\n",
      "ship_date         0\n",
      "units_sold        0\n",
      "unit_price        0\n",
      "unit_cost         0\n",
      "total_revenue     0\n",
      "total_cost        0\n",
      "total_profit      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_raw.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29a66ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_raw.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4efc863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_revenue    0\n",
      "total_cost       0\n",
      "total_profit     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print((df_raw[[\"total_revenue\", \"total_cost\", \"total_profit\"]] < 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5eadc49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gold data inserted into 'sales_gold_region_profit'\n"
     ]
    }
   ],
   "source": [
    "### Gold table\n",
    "\n",
    "import pandas as pd\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "# 🔹 Step 1: Load Cleaned Data\n",
    "df = pd.read_csv(\"sales_silver_cleaned.csv\")\n",
    "\n",
    "# 🔹 Step 2: Aggregate - Total profit by region\n",
    "region_profit = df.groupby(\"region\")[\"total_profit\"].sum().reset_index()\n",
    "\n",
    "# 🟡 Optional: Round values\n",
    "region_profit[\"total_profit\"] = region_profit[\"total_profit\"].round(2)\n",
    "\n",
    "# 🔹 Step 3: Connect to Datastax Astra DB\n",
    "ASTRA_DB_SECURE_BUNDLE_PATH = r'C:/Users/DELL/secure-connect-hello.zip'  # Update to your actual path\n",
    "ASTRA_DB_CLIENT_ID = 'makUuXvvkAWdDyKrsMOvharq'  # Paste from your DB credentials\n",
    "ASTRA_DB_CLIENT_SECRET = '9W6d+7JwkA.HGaJOd62ZXjlvUx9xt_4W5_ctJtw4ES6.CFxK36huoyps6N9GzhtMlkEvRnpD4Nz_BnRc2NJK1Z+D47KsICzqrcZQ23WqZr+mHtZb2I,WqNDYF3,DvJK,'\n",
    "\n",
    "cloud_config = {\n",
    "    'secure_connect_bundle': ASTRA_DB_SECURE_BUNDLE_PATH\n",
    "}\n",
    "\n",
    "auth_provider = PlainTextAuthProvider(ASTRA_DB_CLIENT_ID, ASTRA_DB_CLIENT_SECRET)\n",
    "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
    "session = cluster.connect('hello')  # Replace with your keyspace name\n",
    "\n",
    "# 🔹 Step 4: Insert aggregated data into Gold table\n",
    "insert_query = \"INSERT INTO sales_gold_region_profit (region, total_profit) VALUES (?, ?)\"\n",
    "prepared = session.prepare(insert_query)\n",
    "\n",
    "for _, row in region_profit.iterrows():\n",
    "    session.execute(prepared, (row[\"region\"], float(row[\"total_profit\"])))\n",
    "\n",
    "print(\"✅ Gold data inserted into 'sales_gold_region_profit'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "476a003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gold level Average units sold by item type\n",
    "avg_units = df.groupby(\"item_type\")[\"units_sold\"].mean().reset_index()\n",
    "avg_units[\"avg_units_sold\"] = avg_units[\"units_sold\"].round(2)\n",
    "\n",
    "insert_query = \"INSERT INTO sales_gold_avg_units (item_type, avg_units_sold) VALUES (?, ?)\"\n",
    "prepared = session.prepare(insert_query)\n",
    "\n",
    "for _, row in avg_units.iterrows():\n",
    "    session.execute(prepared, (row[\"item_type\"], float(row[\"avg_units_sold\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a972973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Monthly revenue inserted into 'sales_gold_monthly_revenue'\n"
     ]
    }
   ],
   "source": [
    "### Gold level third table Monthly revenue\n",
    "import pandas as pd\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "# 🔹 Load cleaned silver data\n",
    "df = pd.read_csv(\"sales_silver_cleaned.csv\")\n",
    "\n",
    "# 🔹 Create year_month column (format: YYYY-MM)\n",
    "df[\"order_date\"] = pd.to_datetime(df[\"order_date\"])\n",
    "df[\"year_month\"] = df[\"order_date\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "# 🔹 Group by year_month and calculate total revenue\n",
    "monthly_revenue = df.groupby(\"year_month\")[\"total_revenue\"].sum().reset_index()\n",
    "monthly_revenue[\"total_revenue\"] = monthly_revenue[\"total_revenue\"].round(2)\n",
    "\n",
    "# 🔹 Connect to Astra DB\n",
    "ASTRA_DB_SECURE_BUNDLE_PATH = 'C:/Users/DELL/secure-connect-hello.zip'  # Update path\n",
    "ASTRA_DB_CLIENT_ID = 'makUuXvvkAWdDyKrsMOvharq'         # Replace with your client id\n",
    "ASTRA_DB_CLIENT_SECRET = '9W6d+7JwkA.HGaJOd62ZXjlvUx9xt_4W5_ctJtw4ES6.CFxK36huoyps6N9GzhtMlkEvRnpD4Nz_BnRc2NJK1Z+D47KsICzqrcZQ23WqZr+mHtZb2I,WqNDYF3,DvJK,' # Replace with your secret\n",
    "\n",
    "cloud_config = {\n",
    "    'secure_connect_bundle': ASTRA_DB_SECURE_BUNDLE_PATH\n",
    "}\n",
    "auth_provider = PlainTextAuthProvider(ASTRA_DB_CLIENT_ID, ASTRA_DB_CLIENT_SECRET)\n",
    "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
    "session = cluster.connect('hello')  # replace with your keyspace\n",
    "\n",
    "# 🔹 Insert into Gold table\n",
    "insert_query = \"INSERT INTO sales_gold_monthly_revenue (year_month, total_revenue) VALUES (?, ?)\"\n",
    "prepared = session.prepare(insert_query)\n",
    "\n",
    "for _, row in monthly_revenue.iterrows():\n",
    "    session.execute(prepared, (row[\"year_month\"], float(row[\"total_revenue\"])))\n",
    "\n",
    "print(\"✅ Monthly revenue inserted into 'sales_gold_monthly_revenue'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e8e14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
